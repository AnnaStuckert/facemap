{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 224 size of images\n",
      "Num. train = 1722, Num. val = 574, Num. test = 574\n",
      "Epoch [1/10], Train Loss: 0.0000\n",
      "Epoch [2/10], Train Loss: 0.0000\n",
      "Epoch [3/10], Train Loss: 0.0000\n",
      "Epoch [4/10], Train Loss: 0.0000\n",
      "Epoch [5/10], Train Loss: 0.0000\n",
      "Epoch [6/10], Train Loss: 0.0000\n",
      "Epoch [7/10], Train Loss: 0.0000\n",
      "Epoch [8/10], Train Loss: 0.0000\n",
      "Epoch [9/10], Train Loss: 0.0000\n",
      "Epoch [10/10], Train Loss: 0.0000\n",
      "Test loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pdb\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pdb\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from numpy import random\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from models import Unet\n",
    "\n",
    "\n",
    "def random_cutout(image, label, max_h=50, max_w=50):\n",
    "    \"\"\"\n",
    "    Apply random cutout to both image and label.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        label: The label tensor.\n",
    "        max_h: Maximum height of the cutout box.\n",
    "        max_w: Maximum width of the cutout box.\n",
    "    Returns:\n",
    "        image: Image after cutout.\n",
    "        label: Label after cutout.\n",
    "    \"\"\"\n",
    "    _, h, w = image.shape\n",
    "    cutout_height = random.randint(10, max_h)\n",
    "    cutout_width = random.randint(10, max_w)\n",
    "\n",
    "    # Randomly choose the position for the cutout\n",
    "    top = random.randint(0, h - cutout_height)\n",
    "    left = random.randint(0, w - cutout_width)\n",
    "\n",
    "    # Apply the cutout to the image and label (set to 0)\n",
    "    image[:, top:top + cutout_height, left:left + cutout_width] = 0\n",
    "    label[:, top:top + cutout_height, left:left + cutout_width] = 0\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def adjust_brightness(image, label, brightness_factor=0.2):\n",
    "    \"\"\"\n",
    "    Adjust the brightness of the image and label.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        label: The label tensor.\n",
    "        brightness_factor: Factor by which brightness is adjusted.\n",
    "    Returns:\n",
    "        image: Image after brightness adjustment.\n",
    "        label: Label after brightness adjustment.\n",
    "    \"\"\"\n",
    "    image = TF.adjust_brightness(image, 1 + (random.random() * 2 - 1) * brightness_factor)\n",
    "    # Note: Brightness doesn't affect the label, so we leave it unchanged\n",
    "    return image, label\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def random_jitter(image, max_jitter=0.1):\n",
    "    \"\"\"\n",
    "    Apply random jittering to an image by adding noise to its pixel values.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        max_jitter: The maximum amount of jitter to apply to each pixel.\n",
    "    Returns:\n",
    "        image: The image with jitter applied.\n",
    "    \"\"\"\n",
    "    # Generate random noise with a normal distribution\n",
    "    noise = torch.randn_like(image) * max_jitter  # Gaussian noise\n",
    "    image = image + noise\n",
    "\n",
    "    # Clip the values to be in the valid range [0, 1] for images\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def motion_blur(image, kernel_size=5, angle=45):\n",
    "    \"\"\"\n",
    "    Apply motion blur to an image using a convolution with a motion blur kernel.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        kernel_size: The size of the blur kernel.\n",
    "        angle: The angle of the motion.\n",
    "    Returns:\n",
    "        image: The image after motion blur.\n",
    "    \"\"\"\n",
    "    # Create motion blur kernel\n",
    "    kernel = torch.zeros((kernel_size, kernel_size))\n",
    "\n",
    "    # Define the direction of the blur (this could be any angle, here we use horizontal motion)\n",
    "    center = kernel_size // 2\n",
    "    angle_rad = torch.tensor(angle * torch.pi / 180)  # Convert to radians\n",
    "\n",
    "    # Apply a simple horizontal motion blur\n",
    "    for i in range(kernel_size):\n",
    "        kernel[center, i] = 1\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    # Reshape kernel for convolution (batch size, channels, kernel size)\n",
    "    kernel = kernel.unsqueeze(0).unsqueeze(0)  # Shape (1, 1, kernel_size, kernel_size)\n",
    "\n",
    "    # Apply the kernel using convolution\n",
    "    blurred_image = F.conv2d(image.unsqueeze(0), kernel, padding=kernel_size//2)\n",
    "    return blurred_image.squeeze(0)\n",
    "\n",
    "class FaceMapDataset(Dataset):\n",
    "    def __init__(self, data_file=\"data/dolensek_facemap_softlabels_224.pt\", \n",
    "                 transform=None, \n",
    "                 rotation_degrees=(15, 30),  # Rotation angle range from 15 to 30 degrees\n",
    "                 zoom_range=(0.8, 1.5),  # Zoom range from 0.8 (zoom out) to 1.5 (zoom in)\n",
    "                 blur_radius=(1, 2),  # Tuple for Gaussian blur radius range\n",
    "                 cutout_prob=0.2,  # Probability of applying cutout\n",
    "                 brightness_prob=0.2,  # Probability of applying brightness adjustment\n",
    "                 brightness_factor=0.5,  # Max factor for brightness adjustment\n",
    "                 motion_blur_prob=0.2,  # Probability of applying motion blur\n",
    "                 motion_blur_kernel_size=5,  # Size of the motion blur kernel\n",
    "                 motion_blur_angle=45,  # Angle of the motion blur\n",
    "                 jitter_prob=0.2,  # Probability of applying random jitter\n",
    "                 jitter_max=0.1):  # Maximum jitter value (standard deviation)\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.rotation_degrees = rotation_degrees\n",
    "        self.zoom_range = zoom_range\n",
    "        self.blur_radius = blur_radius\n",
    "        self.cutout_prob = cutout_prob\n",
    "        self.brightness_prob = brightness_prob\n",
    "        self.brightness_factor = brightness_factor\n",
    "        self.motion_blur_prob = motion_blur_prob\n",
    "        self.motion_blur_kernel_size = motion_blur_kernel_size\n",
    "        self.motion_blur_angle = motion_blur_angle\n",
    "        self.jitter_prob = jitter_prob\n",
    "        self.jitter_max = jitter_max\n",
    "        self.data, _, self.targets = torch.load(data_file)\n",
    "\n",
    "    #def __len__(self):\n",
    "    #    return len(self.data) * 5  # Return length * 5 for augmented versions\n",
    "    def __len__(self):\n",
    "        return len(self.data) * 10  # Return length * 10 for augmented versions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Ensure the index stays within bounds by using modulo with the original dataset size\n",
    "        base_index = index % len(self.data)  # This will prevent out-of-bounds errors\n",
    "        aug_type = index // len(self.data)   # This will determine which augmentation to apply\n",
    "\n",
    "        # Load the original image and label\n",
    "        image, label = self.data[base_index].clone(), self.targets[base_index].clone()\n",
    "\n",
    "        # Apply the augmentation based on the `aug_type`\n",
    "        if self.transform is not None:\n",
    "            if aug_type == 1:  # Flipping\n",
    "                image = image.flip([2])\n",
    "                label = label.flip([2])\n",
    "            elif aug_type == 2:  # Rotation\n",
    "                angle = random.uniform(-self.rotation_degrees[1], self.rotation_degrees[1])\n",
    "                image = TF.rotate(image, angle)\n",
    "                label = TF.rotate(label, angle)\n",
    "            elif aug_type == 3:  # Zooming\n",
    "                scale_factor = random.uniform(self.zoom_range[0], self.zoom_range[1])\n",
    "                image = self.zoom(image, scale_factor)\n",
    "                label = self.zoom(label, scale_factor)\n",
    "            elif aug_type == 4:  # Gaussian Blur\n",
    "                radius = (torch.rand(1).item() * (self.blur_radius[1] - self.blur_radius[0])\n",
    "                          + self.blur_radius[0])\n",
    "                image = TF.gaussian_blur(image, kernel_size=int(radius))\n",
    "                # Do not apply blur to the label\n",
    "\n",
    "            # Apply random cutout with probability\n",
    "            if random.random() < self.cutout_prob:\n",
    "                image, label = random_cutout(image, label)\n",
    "\n",
    "            # Apply random brightness adjustment with probability\n",
    "            if random.random() < self.brightness_prob:\n",
    "                image, _ = adjust_brightness(image, label, self.brightness_factor)\n",
    "                # Note that the label is not being adjusted, only the image\n",
    "\n",
    "            # Apply motion blur with probability\n",
    "            if random.random() < self.motion_blur_prob:\n",
    "                image = motion_blur(image, self.motion_blur_kernel_size, self.motion_blur_angle)\n",
    "\n",
    "            # Apply random jittering with probability\n",
    "            if random.random() < self.jitter_prob:\n",
    "                image = random_jitter(image, self.jitter_max)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def zoom(self, img, scale_factor):\n",
    "        # Calculate new dimensions\n",
    "        _, h, w = img.shape\n",
    "        new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "\n",
    "        # Resize and center-crop back to the original size\n",
    "        img = TF.resize(img, [new_h, new_w])\n",
    "        img = TF.center_crop(img, [h, w])\n",
    "        return img\n",
    "\n",
    "\n",
    "# Assuming these are your Unet and convBlock definitions from before\n",
    "class convBlock(nn.Module):\n",
    "    def __init__(self, inCh, nhid, nOp, twod=True, pool=True,\n",
    "                    ker=3, padding=1, pooling=2):\n",
    "        super(convBlock, self).__init__()\n",
    "\n",
    "        if twod:\n",
    "            self.enc1 = nn.Conv2d(inCh, nhid, kernel_size=ker, padding=1)\n",
    "            self.enc2 = nn.Conv2d(nhid, nOp, kernel_size=ker, padding=1)\n",
    "            self.bn = nn.BatchNorm2d(inCh)\n",
    "\n",
    "            if pool:\n",
    "                self.scale = nn.AvgPool2d(kernel_size=pooling)\n",
    "            else:\n",
    "                self.scale = nn.Upsample(scale_factor=pooling)\n",
    "        else:\n",
    "            self.enc1 = nn.Conv3d(inCh, nhid, kernel_size=ker, padding=1)\n",
    "            self.enc2 = nn.Conv3d(nhid, nOp, kernel_size=ker, padding=1)\n",
    "            self.bn = nn.BatchNorm3d(inCh)\n",
    "\n",
    "            if pool:\n",
    "                self.scale = nn.AvgPool3d(kernel_size=pooling)\n",
    "            else:\n",
    "                self.scale = nn.Upsample(scale_factor=pooling)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.scale(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(self.enc1(x))\n",
    "        x = self.act(self.enc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, nhid=8, ker=3, inCh=1, h=224, w=224):\n",
    "        super(Unet, self).__init__()\n",
    "        ### U-net Encoder with 3 downsampling layers\n",
    "        self.uEnc11 = nn.Conv2d(inCh, nhid, kernel_size=ker, padding=1)\n",
    "        self.uEnc12 = nn.Conv2d(nhid, nhid, kernel_size=ker, padding=1)\n",
    "\n",
    "        self.uEnc2 = convBlock(nhid, 2 * nhid, 2 * nhid, pool=True)\n",
    "        self.uEnc3 = convBlock(2 * nhid, 4 * nhid, 4 * nhid, pool=True)\n",
    "        self.uEnc4 = convBlock(4 * nhid, 8 * nhid, 8 * nhid, pool=True)  # unhashed\n",
    "        self.uEnc5 = convBlock(8 * nhid, 16 * nhid, 16 * nhid, pool=True)  # unhashed\n",
    "\n",
    "        ### U-net decoder \n",
    "        self.dec5 = convBlock(16 * nhid, 8 * nhid, 8 * nhid, pool=False)  # unhashed\n",
    "        self.dec4 = convBlock(16 * nhid, 4 * nhid, 4 * nhid, pool=False)  # unhashed\n",
    "        self.dec3 = convBlock(4 * nhid, 2 * nhid, 2 * nhid, pool=False, pooling=2)\n",
    "        self.dec2 = convBlock(4 * nhid, nhid, nhid, pool=False, pooling=2)\n",
    "\n",
    "        self.dec11 = nn.Conv2d(2 * nhid, nhid, kernel_size=ker, padding=1)\n",
    "        self.dec12 = nn.Conv2d(nhid, 1, kernel_size=ker, padding=1)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "    def encoder(self, x_in):\n",
    "        ### Unet Encoder\n",
    "        x = []\n",
    "        x.append(self.act(self.uEnc12(self.act(self.uEnc11(x_in)))))\n",
    "        x.append(self.uEnc2(x[-1]))\n",
    "        x.append(self.uEnc3(x[-1]))\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x_enc):\n",
    "        x = self.dec3(x_enc[-1])\n",
    "        x = torch.cat((x, x_enc[-2]), dim=1)\n",
    "        x = self.dec2(x)\n",
    "        x = torch.cat((x, x_enc[-3]), dim=1)\n",
    "        fmap = self.act(self.dec11(x))\n",
    "        x = self.dec12(fmap)\n",
    "        return x, fmap\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Unet encoder result\n",
    "        x_enc = self.encoder(x)\n",
    "        # Outputs for MSE\n",
    "        xHat, fmap = self.decoder(x_enc)\n",
    "        return xHat, fmap\n",
    "\n",
    "\n",
    "# Ensemble Model\n",
    "class UNetEnsemble(nn.Module):\n",
    "    def __init__(self, num_models=5, nhid=8, ker=3, inCh=1, h=224, w=224):\n",
    "        super(UNetEnsemble, self).__init__()\n",
    "        self.models = nn.ModuleList([Unet(nhid=nhid, ker=ker, inCh=inCh, h=h, w=w).to(device) for _ in range(num_models)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        predictions = []\n",
    "        feature_maps = []\n",
    "\n",
    "        # Forward pass through all models in the ensemble\n",
    "        for model in self.models:\n",
    "            pred, fmap = model(x)  # Assuming each model returns (prediction, feature_maps)\n",
    "            predictions.append(pred)\n",
    "            feature_maps.append(fmap)\n",
    "\n",
    "        # Average the predictions from all models\n",
    "        ensemble_prediction = torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "        return ensemble_prediction, feature_maps\n",
    "\n",
    "\n",
    "\n",
    "### Make dataset\n",
    "dataset = FaceMapDataset(transform=\"test\")\n",
    "\n",
    "x = dataset[0][0]\n",
    "dim = x.shape[-1]\n",
    "print(f\"Using {dim} size of images\")\n",
    "N = len(dataset)\n",
    "\n",
    "# Randomization\n",
    "indices = np.random.permutation(N)\n",
    "train_indices = indices[:int(0.6 * N)]\n",
    "valid_indices = indices[int(0.6 * N):int(0.8 * N)]\n",
    "test_indices = indices[int(0.8 * N):]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "# Initialize loss and metrics\n",
    "loss_fun = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "# Initiliaze input dimensions\n",
    "num_train = len(train_sampler)\n",
    "num_valid = len(valid_sampler)\n",
    "num_test = len(test_sampler)\n",
    "print(f\"Num. train = {num_train}, Num. val = {num_valid}, Num. test = {num_test}\")\n",
    "\n",
    "# Initialize dataloaders\n",
    "loader_train = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "loader_valid = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    sampler=valid_sampler,\n",
    ")\n",
    "loader_test = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    sampler=test_sampler,\n",
    ")\n",
    "\n",
    "nValid = len(loader_valid)\n",
    "nTrain = len(loader_train)\n",
    "nTest = len(loader_test)\n",
    "\n",
    "# Training Loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble_model = UNetEnsemble(num_models=5, nhid=8, ker=3, inCh=1, h=224, w=224).to(device)\n",
    "optimizer = torch.optim.Adam(ensemble_model.parameters(), lr=0.001)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "# Assuming `loader_train` is the DataLoader for training\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    ensemble_model.train()\n",
    "    tr_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(loader_train):  # Assuming loader_train is your DataLoader\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass through the ensemble model\n",
    "        ensemble_prediction, feature_maps = ensemble_model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fun(ensemble_prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {tr_loss / (i + 1):.4f}\")\n",
    "\n",
    "\n",
    "# Inference and Feature Map Visualization\n",
    "ensemble_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(loader_test):  # Assuming loader_test is your test DataLoader\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass through the ensemble model\n",
    "        ensemble_prediction, feature_maps = ensemble_model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fun(ensemble_prediction, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # Convert outputs to numpy for plotting\n",
    "        img = inputs.squeeze().detach().cpu().numpy()\n",
    "        pred = ensemble_prediction.squeeze().detach().cpu().numpy()\n",
    "        labels_np = labels.squeeze().cpu().numpy()\n",
    "\n",
    "        # Visualize feature maps from all models in the ensemble\n",
    "        for j, fmap in enumerate(feature_maps):\n",
    "            fmap_mean = fmap.mean(1).squeeze().cpu().numpy()  # Take the mean over the channels (axis=1)\n",
    "\n",
    "            # Plotting\n",
    "            plt.clf()\n",
    "            plt.figure(figsize=(12, 9))\n",
    "\n",
    "            plt.subplot(3, 4, 1)\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "            plt.title(\"Input Image\")\n",
    "\n",
    "            plt.subplot(3, 4, 2)\n",
    "            plt.imshow(labels_np)\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "            plt.subplot(3, 4, 3)\n",
    "            plt.imshow(pred)\n",
    "            plt.title(\"Ensemble Prediction\")\n",
    "\n",
    "            plt.subplot(3, 4, 4)\n",
    "            plt.imshow(fmap_mean)\n",
    "            plt.title(f\"Feature Map Mean (Model {j+1})\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"preds/test_{i:03d}_model_{j+1}.jpg\")\n",
    "            plt.close()\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    val_loss = val_loss / (i + 1)\n",
    "    print(f\"Test loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
