{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([168, 1, 224, 224])\n",
      "[array([ 88.44916 ,  75.308556, 102.91697 ,  91.09162 ,  90.422035,\n",
      "       102.27129 ,  69.37795 ,  93.72214 , 207.4798  , 120.02725 ,\n",
      "       216.68658 , 133.83743 , 210.11032 , 149.62051 , 148.95093 ,\n",
      "       124.630646, 139.0865  , 139.75609 , 143.03229 , 150.93576 ,\n",
      "       137.77126 , 191.05107 , 123.30344 , 195.65445 ], dtype=float32), array([ 83.38663,  76.62381,  99.1697 ,  90.434  ,  86.67476, 102.27129,\n",
      "        66.2883 ,  93.06451, 208.99353, 125.9459 , 214.25456, 136.46796,\n",
      "       207.67828, 151.59338, 145.86127, 125.9459 , 136.65446, 137.12556,\n",
      "       139.28499, 149.62051, 132.70872, 192.36632, 117.58327, 195.65445],\n",
      "      dtype=float32), array([ 85.630936,  76.62381 ,  98.78349 ,  93.06451 ,  84.9733  ,\n",
      "       104.24418 ,  67.21735 ,  94.37976 , 211.8955  , 131.20692 ,\n",
      "       215.84123 , 143.04424 , 208.60733 , 154.88153 , 143.50217 ,\n",
      "       124.630646, 136.26826 , 137.7832  , 136.26826 , 149.62051 ,\n",
      "       132.32251 , 189.07817 , 114.56657 , 197.62733 ], dtype=float32), array([ 87.79154 ,  75.308556, 105.547485,  93.72214 ,  87.1339  ,\n",
      "       102.27129 ,  67.405075,  93.06451 , 205.50693 , 117.396736,\n",
      "       218.65948 , 137.7832  , 210.76793 , 148.30525 , 150.9238  ,\n",
      "       131.20692 , 141.71703 , 141.72897 , 144.34753 , 150.93576 ,\n",
      "       135.14073 , 190.39343 , 121.988174, 198.28497 ], dtype=float32), array([ 85.24473 ,  75.308556,  99.0549  ,  93.72214 ,  83.27183 ,\n",
      "       103.586555,  63.54301 ,  93.72214 , 205.5906  , 121.342514,\n",
      "       212.1669  , 134.49507 , 205.5906  , 149.62051 , 147.71938 ,\n",
      "       133.17981 , 137.19731 , 141.07135 , 141.14308 , 151.59338 ,\n",
      "       130.62105 , 193.02394 , 118.12611 , 195.65445 ], dtype=float32)]\n",
      "<class 'list'>\n",
      "Data saved to C:\\Users\\avs20\\Documents\\GitHub\\facemap\\data\\dolensek_processed_images_labels_TEST\\dolensek_test.pt\n",
      "New keypoints saved to C:\\Users\\avs20\\Documents\\GitHub\\facemap\\data\\dolensek_processed_images_labels_TEST\\labels.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avs20\\AppData\\Local\\Temp\\ipykernel_27952\\3228256309.py:121: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  all_labels_tensor = torch.tensor(all_labels)  # Convert labels to tensor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the main directory containing subfolders\n",
    "IMG_LOC = r\"C:\\Users\\avs20\\Documents\\GitHub\\facemap\\data\\dolensek2020\"\n",
    "\n",
    "# Path to save the new images, labels, and CSV file\n",
    "output_dir = r\"C:\\Users\\avs20\\Documents\\GitHub\\facemap\\data\\dolensek_processed_images_labels_TEST\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Prepare a list to store the new keypoints for CSV\n",
    "new_keypoints = []\n",
    "\n",
    "# Function to apply random crop and resize to 224x224\n",
    "def random_crop_and_resize(img, keypoints, target_size=224):\n",
    "    # Get the original image size\n",
    "    img = img.convert(\"L\")  # Convert to grayscale (1 channel) - just remove this line to get the image in RGB\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Find the shortest side\n",
    "    crop_size = min(img_width, img_height)\n",
    "    \n",
    "    # Randomly choose the top-left corner for the crop\n",
    "    left = random.randint(400, img_width - crop_size)\n",
    "    top = random.randint(0, img_height - crop_size)\n",
    "    \n",
    "    # Apply the crop\n",
    "    img_cropped = img.crop((left, top, left + crop_size, top + crop_size))\n",
    "    \n",
    "    # Resize the cropped image to 224x224\n",
    "    img_resized = img_cropped.resize((target_size, target_size))\n",
    "    \n",
    "    # Adjust the keypoints based on the crop and resize\n",
    "    # Adjust for the crop (shift the keypoints by the crop's top-left corner)\n",
    "    adjusted_keypoints = []\n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        x = keypoints[i] - left\n",
    "        y = keypoints[i + 1] - top\n",
    "        adjusted_keypoints.append(x)\n",
    "        adjusted_keypoints.append(y)\n",
    "    \n",
    "    # Adjust for the resizing (scale keypoints to the new image size)\n",
    "    scale_x = target_size / crop_size\n",
    "    scale_y = target_size / crop_size\n",
    "    \n",
    "    adjusted_keypoints = [\n",
    "        adjusted_keypoints[i] * scale_x if i % 2 == 0 else adjusted_keypoints[i] * scale_y\n",
    "        for i in range(len(adjusted_keypoints))\n",
    "    ]\n",
    "    \n",
    "    return img_resized, adjusted_keypoints\n",
    "\n",
    "# Prepare lists to store data to be saved\n",
    "all_images = []\n",
    "all_labels = []\n",
    "all_filenames = []\n",
    "\n",
    "# Loop through each subfolder\n",
    "for subfolder in os.scandir(IMG_LOC):\n",
    "    if subfolder.is_dir():\n",
    "        subfolder_path = subfolder.path\n",
    "        \n",
    "        # Get all image files in the current subfolder (filtering out non-image files)\n",
    "        image_files = [f for f in os.listdir(subfolder_path) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "        \n",
    "        # Check if there are images in the folder\n",
    "        if not image_files:\n",
    "            continue\n",
    "        \n",
    "        # Check for the presence of a CSV file in the subfolder\n",
    "        csv_files = [f for f in os.listdir(subfolder_path) if f.endswith('.csv')]\n",
    "        if csv_files:\n",
    "            csv_path = os.path.join(subfolder_path, csv_files[0])  # Assuming one CSV per subfolder\n",
    "            labels_o = pd.read_csv(csv_path)\n",
    "\n",
    "            # Process the CSV: Skip first two rows and select relevant columns\n",
    "            labels_o = labels_o.iloc[2:, 2:]\n",
    "            target_o = labels_o.iloc[:, 1:].values\n",
    "            target_o = np.array(target_o, dtype=np.float32)\n",
    "            #print(f\"Processed labels for subfolder: {os.path.basename(subfolder_path)}\")\n",
    "        else:\n",
    "            print(f\"No CSV file found for subfolder: {os.path.basename(subfolder_path)}\")\n",
    "            target_o = None  # Set to None if no CSV is found\n",
    "\n",
    "        # Loop through each image in the folder and process it\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            # Construct the full image path\n",
    "            image_path = os.path.join(subfolder_path, image_file)\n",
    "            \n",
    "            # Open the image\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "\n",
    "            \n",
    "            # Get corresponding keypoints from target_o\n",
    "            label = target_o[i] if target_o is not None else None\n",
    "            \n",
    "            # Apply random crop and resize the image and keypoints\n",
    "            img_resized, adjusted_keypoints = random_crop_and_resize(img, label)\n",
    "            \n",
    "            # Save the resized image to the output folder\n",
    "            output_image_path = os.path.join(output_dir, f\"{os.path.basename(subfolder_path)}_{image_file}\")\n",
    "            img_resized.save(output_image_path)\n",
    "            \n",
    "            # Append the image and its label\n",
    "            all_images.append(transforms.ToTensor()(img_resized))  # Convert image to tensor\n",
    "            all_labels.append(np.array(adjusted_keypoints, dtype=np.float32))  # Convert keypoints to numpy array\n",
    "            all_filenames.append(output_image_path)  # Keep track of the filenames\n",
    "            \n",
    "            # Store the adjusted keypoints for CSV\n",
    "            new_keypoints.append(adjusted_keypoints)\n",
    "\n",
    "# Convert lists to tensors\n",
    "all_images_tensor = torch.stack(all_images)  # Stack images into a single tensor\n",
    "all_labels_tensor = torch.tensor(all_labels)  # Convert labels to tensor\n",
    "\n",
    "# Save the images and labels as a .pt file\n",
    "save_path = os.path.join(output_dir, \"dolensek_test.pt\")\n",
    "print(all_images_tensor.shape)\n",
    "\n",
    "print(all_labels[:5])  # Print the first 5 labels to check their content\n",
    "print(type(all_labels))  # Ensure it's a list\n",
    "\n",
    "torch.save({\n",
    "    'images': all_images_tensor,\n",
    "    'labels': all_labels_tensor\n",
    "#    'filenames': all_filenames\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Data saved to {save_path}\")\n",
    "\n",
    "# Save the new keypoints as a CSV file\n",
    "keypoints_df = pd.DataFrame(new_keypoints)\n",
    "csv_save_path = os.path.join(output_dir, \"labels.csv\")\n",
    "keypoints_df.to_csv(csv_save_path, index=False, header=False)  # No header, just the keypoints\n",
    "\n",
    "print(f\"New keypoints saved to {csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define the path to the saved .pt file\n",
    "pt_file_path = r\"C:\\Users\\avs20\\Documents\\GitHub\\facemap\\data\\dolensek_processed_images_labels\\dolensek_test.pt\"\n",
    "\n",
    "# Load the data from the .pt file\n",
    "data = torch.load(pt_file_path)\n",
    "\n",
    "# Extract images, labels, and filenames from the loaded data\n",
    "images = data['images']  # Tensor of images\n",
    "labels = data['labels']  # Tensor of keypoints (shape: N x 2*K)\n",
    "#filenames = data['filenames']  # List of filenames\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Function to visualize a grayscale image with its keypoints\n",
    "def visualize_image_with_keypoints(img_tensor, keypoints):\n",
    "    # Convert the tensor image back to a numpy array (assuming it's in [0, 1] range)\n",
    "    # Grayscale images are single-channel, so we need to handle that.\n",
    "    if img_tensor.ndimension() == 3 and img_tensor.size(0) == 1:  # Shape: (1, H, W)\n",
    "        img = img_tensor.squeeze(0).numpy()  # Remove channel dimension\n",
    "    elif img_tensor.ndimension() == 2:  # Shape: (H, W)\n",
    "        img = img_tensor.numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected image dimensions: {img_tensor.shape}\")\n",
    "\n",
    "    # Create a matplotlib figure\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap=\"gray\")  # Use grayscale colormap\n",
    "    plt.axis('off')  # Hide axes\n",
    "\n",
    "    # Plot the keypoints\n",
    "    if keypoints is not None:\n",
    "        # The keypoints are stored as [x1, y1, x2, y2, ..., xK, yK], so we split them\n",
    "        xs = keypoints[0::2]  # x coordinates (even indices)\n",
    "        ys = keypoints[1::2]  # y coordinates (odd indices)\n",
    "\n",
    "        # Plot the keypoints as red circles\n",
    "        plt.scatter(xs, ys, c=\"red\", marker=\"o\")\n",
    "\n",
    "    # Show the image\n",
    "    plt.show()\n",
    "\n",
    "# Loop through the images and visualize them with keypoints\n",
    "for i in range(len(images)):\n",
    "    img_tensor = images[i]  # Get the image tensor\n",
    "    keypoints = labels[i].numpy()  # Get the corresponding keypoints\n",
    "\n",
    "    # Visualize the image and keypoints\n",
    "    #print(f\"Visualizing {filenames[i]}\")\n",
    "    visualize_image_with_keypoints(img_tensor, keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([168, 1, 224, 224])\n",
      "torch.Size([168, 24])\n",
      "torch.Size([168, 1, 224, 224])\n",
      "(168, 24)\n",
      "Data and labels are loaded and transformed.\n",
      "Saved in data/dolensek_test_224_new.pt\n",
      "Final x shape: torch.Size([168, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# put into format as raghav's make_dataset script\n",
    "\n",
    "# Define the path to the saved .pt file\n",
    "pt_file_path = r\"C:\\Users\\avs20\\Documents\\GitHub\\facemap\\data\\dolensek_processed_images_labels_TEST\\dolensek_test.pt\"\n",
    "\n",
    "# Load the data from the .pt file\n",
    "data = torch.load(pt_file_path)\n",
    "\n",
    "# Extract images, labels, and filenames from the loaded data\n",
    "x = data['images']  # Tensor of images\n",
    "y = data['labels']  # Tensor of keypoints (shape: N x 2*K)\n",
    "#filenames = data['filenames']  # List of filenames\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Transformations for `x` and `y`\n",
    "#x = x.unsqueeze(1)  # Add channel dimension to `x`\n",
    "y = y.numpy()  # Convert `y` to numpy if needed\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Save final transformed data\n",
    "final_save_path = \"data/dolensek_test_224_new.pt\"\n",
    "torch.save((x, y), final_save_path)\n",
    "\n",
    "print(f\"Data and labels are loaded and transformed.\\nSaved in {final_save_path}\")\n",
    "print(\"Final x shape:\", x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([168, 1, 224, 224])\n",
      "torch.Size([168, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# make soft labels\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import io\n",
    "\n",
    "# Load data\n",
    "x, y = torch.load(\"data/dolensek_test_224_new.pt\")\n",
    "h, w = x[0].shape[1], x[1].shape[2]  # Image height and width\n",
    "print(x.shape)\n",
    "\n",
    "# Set the sigma for Gaussian filter\n",
    "sigma = 3  # Increase from original 3 to 5\n",
    "\n",
    "# Initialize the tensor for soft labels\n",
    "softlabels = torch.zeros(x.shape)\n",
    "\n",
    "# Loop through each set of keypoints and generate soft labels\n",
    "for i in range(len(y)):\n",
    "    mask = np.zeros((h, w))  # Initialize an empty mask of zeros\n",
    "    \n",
    "    # Get the keypoints, remove NaNs and separate x, y coordinates\n",
    "    y_i = y[i][~np.isnan(y[i])]\n",
    "    idx_x, idx_y = y_i[1::2].astype(int), y_i[::2].astype(int)\n",
    "    \n",
    "    # Ensure indices are within bounds (0 to 223 for a 224x224 image)\n",
    "    idx_x = np.clip(idx_x, 0, h - 1)  # Clamp x indices to be between 0 and h-1\n",
    "    idx_y = np.clip(idx_y, 0, w - 1)  # Clamp y indices to be between 0 and w-1\n",
    "\n",
    "    # Mark the valid keypoints in the mask\n",
    "    mask[idx_x, idx_y] = 1\n",
    "    \n",
    "    # Apply Gaussian filter to the mask to generate soft labels\n",
    "    label = gaussian_filter(mask, sigma=sigma)\n",
    "    \n",
    "    # Store the soft labels in the tensor\n",
    "    softlabels[i, 0] = torch.Tensor(label)\n",
    "\n",
    "# Save the data including soft labels\n",
    "torch.save((x, y, softlabels), \"data/dolensek_test_softlabels_224.pt\")\n",
    "\n",
    "# Print the shape of the tensor (for debugging purposes)\n",
    "print(x.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
